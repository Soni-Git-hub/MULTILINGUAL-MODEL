{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "\n",
    "!pip install -U datasets\n",
    "\n",
    "!pip install gradio\n",
    "\n",
    "!pip install librosa\n",
    "\n",
    "!pip install soundfile\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset=load_dataset(\"librispeech_asr\",split='train.clean.100',streaming=True,trust_remote_code=True)\n",
    "\n",
    "example = next(iter(dataset))\n",
    "\n",
    "dataset_head = dataset.take(5)\n",
    "list(dataset_head)\n",
    "\n",
    "list(dataset_head) [2]\n",
    "\n",
    "example\n",
    "\n",
    "from IPython.display import Audio as IPythonAudio\n",
    "IPythonAudio(example[\"audio\"] [\"array\"],rate=example[\"audio\"][\"sampling_rate\"])\n",
    "\n",
    "from transformers import pipeline\n",
    "asr = pipeline(task=\"automatic-speech-recognition\",\n",
    "               model=\"openai/whisper-large-v3\")\n",
    "\n",
    "asr.feature_extractor.sampling_rate\n",
    "\n",
    "example ['audio'] ['sampling_rate']\n",
    "\n",
    "asr(example[\"audio\"][\"array\"])\n",
    "\n",
    "example[\"text\"]\n",
    "\n",
    "import os\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Blocks()\n",
    "\n",
    "def transcribe_speech(filepath):\n",
    "    if filepath is None:\n",
    "        gr.Warning(\"No audio found, please retry.\")\n",
    "        return \"\"\n",
    "    output = asr(filepath)\n",
    "    return output[\"text\"]\n",
    "\n",
    "mic_transcribe = gr.Interface(\n",
    "    fn=transcribe_speech,\n",
    "    inputs=gr.Audio(sources=\"microphone\",\n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\",\n",
    "                       lines=3),\n",
    "    allow_flagging=\"never\")\n",
    "\n",
    "file_transcribe = gr.Interface(\n",
    "    fn=transcribe_speech,\n",
    "    inputs=gr.Audio(sources=\"upload\",\n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\",\n",
    "                       lines=3),\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "\n",
    "with demo:\n",
    "    gr.TabbedInterface(\n",
    "        [mic_transcribe,\n",
    "         file_transcribe],\n",
    "        [\"Transcribe Microphone\",\n",
    "         \"Transcribe Audio File\"],\n",
    "    )\n",
    "\n",
    "demo.launch(debug=True)\n",
    "\n",
    "demo.close()\n",
    "\n",
    "import soundfile as sf\n",
    "import io\n",
    "\n",
    "audio, sampling_rate = sf.read('/gudilo_badilo_song.mp3')\n",
    "\n",
    "sampling_rate\n",
    "\n",
    "asr.feature_extractor.sampling_rate\n",
    "\n",
    "audio.shape\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "audio_transposed = np.transpose(audio)\n",
    "\n",
    "audio_transposed.shape\n",
    "\n",
    "import librosa\n",
    "\n",
    "audio_mono = librosa.to_mono(audio_transposed)\n",
    "\n",
    "IPythonAudio(audio_mono,\n",
    "             rate=sampling_rate)\n",
    "\n",
    "asr(audio_mono)\n",
    "\n",
    "sampling_rate\n",
    "\n",
    "asr.feature_extractor.sampling_rate\n",
    "\n",
    "audio_16KHz = librosa.resample(audio_mono,\n",
    "                               orig_sr=sampling_rate,\n",
    "                               target_sr=16000)\n",
    "\n",
    "asr(\n",
    "    audio_16KHz,\n",
    "    chunk_length_s=30, # 30 seconds\n",
    "    batch_size=4,\n",
    "    return_timestamps=True,\n",
    ")[\"chunks\"]\n",
    "\n",
    "import gradio as gr\n",
    "demo = gr.Blocks()\n",
    "\n",
    "def transcribe_long_form(filepath):\n",
    "    if filepath is None:\n",
    "        gr.Warning(\"No audio found, please retry.\")\n",
    "        return \"\"\n",
    "    output = asr(\n",
    "      filepath,\n",
    "      max_new_tokens=256,\n",
    "      chunk_length_s=30,\n",
    "      batch_size=8,\n",
    "    )\n",
    "    return output[\"text\"]\n",
    "\n",
    "mic_transcribe = gr.Interface(\n",
    "    fn=transcribe_long_form,\n",
    "    inputs=gr.Audio(sources=\"microphone\",\n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\",\n",
    "                       lines=3),\n",
    "    allow_flagging=\"never\")\n",
    "\n",
    "file_transcribe = gr.Interface(\n",
    "    fn=transcribe_long_form,\n",
    "    inputs=gr.Audio(sources=\"upload\",\n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\",\n",
    "                       lines=3),\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "\n",
    "with demo:\n",
    "    gr.TabbedInterface(\n",
    "        [mic_transcribe,\n",
    "         file_transcribe],\n",
    "        [\"Transcribe Microphone\",\n",
    "         \"Transcribe Audio File\"],\n",
    "    )\n",
    "demo.launch(debug=True)\n",
    "\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
